{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fcwt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from scipy import signal\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from vit_pytorch.vit_3d import ViT\n",
    "from scipy.ndimage import zoom\n",
    "import torch.cuda.amp as amp\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "x = pickle.load(open('data_preprocessed_python/s01.dat', 'rb'), encoding='latin1')\n",
    "data = x['data']\n",
    "labels = x['labels']\n",
    "\n",
    "relevant_channels = data[:, :32, :]\n",
    "relevant_labels = labels[:, :2]\n",
    "\n",
    "classes = []\n",
    "for trial in range(40):\n",
    "    # 4 valence-arousal classes\n",
    "    valence, arousal = relevant_labels[trial][0], relevant_labels[trial][1]\n",
    "    cls = 0 if valence < 4.5 and arousal < 4.5 else \\\n",
    "                    1 if valence < 4.5 else \\\n",
    "                    2 if arousal < 4.5 else 3\n",
    "    classes.append(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize constant variables\n",
    "# paramaters for calculating cwt, not to be changed\n",
    "fs = 128 \n",
    "f0 = 4 # lowest frequency\n",
    "f1 = 45 # highest frequency\n",
    "fn = 32 # number of frequencies, match channel number for square frame\n",
    "target_shape = (32, 64, 256)\n",
    "\n",
    "# parameters for model training etc., may be changed to adjust balance between performance and cost\n",
    "# TODO: consider evolutionary approach to finding optimal parameters\n",
    "BATCH_SIZE = 1\n",
    "IMAGE_SIZE = 2048\n",
    "PATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cwt = np.zeros((1024, 8064))\n",
    "\n",
    "for channel in range(32):    \n",
    "    signal = relevant_channels[0][channel]\n",
    "    _, current_cwt = fcwt.cwt(signal, fs, f0, f1, fn)\n",
    "    start = channel * fn\n",
    "    end = (channel + 1) * fn\n",
    "    total_cwt[start:end, :] = abs(current_cwt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame shape: (3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# convert 2D time sample x channel-frequency format (x, y) to 3D channel x frequency x time format (x, y, z)\n",
    "# each 'frame' in all_frames is a 2D image showing each channel's CWT value for that time sample\n",
    "all_frames = []\n",
    "\n",
    "for sample in range(8064):\n",
    "    frame = np.zeros((32, 32))\n",
    "    for channel in range(32):\n",
    "        start = channel * fn\n",
    "        end = (channel + 1) * fn\n",
    "        frame[:, channel] = total_cwt[start:end, sample]\n",
    "\n",
    "    # formatting for .gif format, not neccessary\n",
    "    # append(frame) if creating data for training\n",
    "    \n",
    "    # normalize frame\n",
    "    norm_frame = (frame - frame.min()) / (frame.max() - frame.min())\n",
    "    # scale to 0-255\n",
    "    scaled_frame = (norm_frame * 255).astype(np.uint8)\n",
    "\n",
    "    # stack for RGB\n",
    "    frame_rgb = np.stack((scaled_frame,) * 3, axis=0)\n",
    "    frame_rgb = np.clip(frame_rgb, 0, 255).astype(np.uint8)\n",
    "\n",
    "    if sample == 0:\n",
    "        print(\"Frame shape:\", frame_rgb.shape)\n",
    "\n",
    "    all_frames.append(frame_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (8064, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# write .gif file\n",
    "from array2gif import write_gif\n",
    "gif_dataset = np.array(all_frames)\n",
    "print(\"Dataset shape:\", gif_dataset.shape)\n",
    "write_gif(gif_dataset, 'test.gif', fps = 128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
